{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dev Notes\n",
    "\n",
    "Gonna use pandas directly. Shouldn't be any consistency issues as these excels are machine generated, \n",
    "and will take forever with databaker as excessive depth (databaker has diminishing returns on speed of lookups). \n",
    "\n",
    "\n",
    "## Usage\n",
    "\n",
    "1.) CHANGE THE variables `importsInFile` and `exportsInFile` in the below cell.\n",
    "\n",
    "2.) Use `Cell->Run All` from the above ribbon.\n",
    "<br>\n",
    "<br>\n",
    "NOTE - this is not quick, expect it to take 5-10 mins and just leave it to run, it's fine.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from databakerUtils.v4Functions import v4Integers\n",
    "import requests\n",
    "import glob\n",
    "\n",
    "# ###########################\n",
    "# CHANGE INPUT FILENAMES HERE\n",
    "# ###########################\n",
    "\n",
    "location = '*.xlsx'\n",
    "files = glob.glob(location)\n",
    "importsInFile = [file for file in files if 'import' in file][0]\n",
    "exportsInFile = [file for file in files if 'export' in file][0]\n",
    "\n",
    "dfI = pd.read_excel(importsInFile, 'Country by Commodity Import')   # create imports dataframe\n",
    "dfE = pd.read_excel(exportsInFile, 'Country by Commodity Export')   # create exports dataframe\n",
    "\n",
    "# Sanity check imports dataframe - literally just so we can eyeball the first three lines.\n",
    "dfI[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check exports dataframe - literally just so we can eyeball the first three lines.\n",
    "dfE[:3]\n",
    "\n",
    "# Functions we'll reuse a few times.\n",
    "\n",
    "def fixTime(cell):\n",
    "    \"\"\"\n",
    "    Takes the horrible date i.e '1998JAN' and returns something cmd friendly. i.e 1998JAN becomes 'Jan-98'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # get rid of pointess quotes\n",
    "    cell = cell.replace(\"'\", \"\")\n",
    "    \n",
    "    # Some validation, as this is most likely place to encounter 'fun'\n",
    "    assert len(cell) == 7, \"Aborting. Expecting 'date' to be 7 characters long (eg 1998JAN). We got: \" + cell\n",
    "    \n",
    "    try:\n",
    "        pointless = int(cell[:4]) # hacky\n",
    "    except:\n",
    "        raise ValueError(\"First 4 characters of 'date' should be a year, we got: \" + cell[:4])\n",
    "        \n",
    "    return cell[-3:].title() + \"-\" + cell[2:4]\n",
    "\n",
    "url = 'https://api.beta.ons.gov.uk/v1/code-lists/sitc/editions/one-off/codes'\n",
    "r = requests.get(url)\n",
    "wholeDict = r.json()\n",
    "commodityDict = {}\n",
    "for item in wholeDict['items']:\n",
    "    commodityDict.update({item['code']:item['label']})\n",
    "def CommodityLabels(value):\n",
    "    #returns sitc labels from api\n",
    "    return commodityDict[value]\n",
    "\n",
    "url = 'https://api.beta.ons.gov.uk/v1/code-lists/countries-and-territories/editions/one-off/codes'\n",
    "r = requests.get(url)\n",
    "wholeDict = r.json()\n",
    "countryDict = {}\n",
    "for item in wholeDict['items']:\n",
    "    countryDict.update({item['code']:item['label']})\n",
    "def CountryLabels(value):\n",
    "    #returns countries-and-territories labels from api\n",
    "    return countryDict[value]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation Script\n",
    "\n",
    "At this point the dataframes and function are loaded (by executing previous cells), so executing the following cell creates the \n",
    "final v4 file.\n",
    "\n",
    "## Explanation\n",
    "We're just gonna pivot the data a column at a time. Creating a list containing dataframes - then concatenating them into \n",
    "one \"master\" dataframe which is written to csv.\n",
    "\n",
    "If you think of the source data (see sanity checks above), each of the sub-datasets we're creating is made from\n",
    "the first-3-columns + cmd bumf and 1 * time column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "allFrames = [] # list for holding each sub-dataframe\n",
    "\n",
    "# TODO - no real need to have both sources in memory at the same time\n",
    "num = 0\n",
    "for source in [dfI, dfE]:\n",
    "        \n",
    "    num += 1 # simeple counter for feedback.\n",
    "    \n",
    "    # For each date column:\n",
    "    for dateCol in source.columns.values[3:]:\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        df[\"v4_0\"] = source[dateCol]\n",
    "        \n",
    "        df[\"mmm-yy\"] = fixTime(dateCol)\n",
    "        df[\"Time\"] = fixTime(dateCol)\n",
    "        \n",
    "        df[\"uk-only\"] = \"K02000001\"\n",
    "        df[\"Geography\"] = \"United Kingdom\"\n",
    "        \n",
    "        # For the three topic dimensions, they appear to have put the code and label together.\n",
    "        # just need to split them out\n",
    "        \n",
    "        # TODO - messy. Less lambda more func\n",
    "        # NOTE - replacing \"/\" with \"-\" as \"/\" has syntactical meaning in Cypher and breaks dimension importer\n",
    "        df[\"sitc\"] = source[\"COMMODITY\"].map(lambda x: x.split(\" \")[0]).str.replace(\"/\", \"-\")\n",
    "        df[\"StandardIndustrialTradeClassification\"] = source[\"COMMODITY\"].map(lambda x: \" \".join(x.split(\" \")[1:]))\n",
    "        \n",
    "        df[\"countries-and-territories\"] = source[\"COUNTRY\"].map(lambda x: x.split(\" \")[0])\n",
    "        df[\"CountriesAndTerritories\"] = source[\"COUNTRY\"].map(lambda x: \" \".join(x.split(\" \")[1:]))\n",
    "        \n",
    "        df[\"trade-direction\"] = source[\"DIRECTION\"].map(lambda x: x.split(\" \")[0])\n",
    "        df[\"Direction\"] = source[\"DIRECTION\"].map(lambda x: x.split(\" \")[1])\n",
    "        \n",
    "        allFrames.append(df)\n",
    "        print(\"Generated sub-dataframe for {dc} from source {n} of 2.\".format(dc=dateCol, n=num))\n",
    "    \n",
    "allDf = pd.concat(allFrames)\n",
    "\n",
    "allDf['v4_0'] = allDf['v4_0'].apply(v4Integers) #changes floats to string-integers\n",
    "\n",
    "allDf['CountriesAndTerritories'] = allDf['countries-and-territories'].apply(CountryLabels) #change country labels\n",
    "allDf['StandardIndustrialTradeClassification'] = allDf['sitc'].apply(CommodityLabels) #change commodity labels\n",
    "\n",
    "allDf.to_csv(\"v4_Trade.csv\", index=False) # output to csv\n",
    "print(\"v4 File successfully generated.\")\n",
    "\n",
    "# Sanity check output, 5 lines only\n",
    "allDf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
